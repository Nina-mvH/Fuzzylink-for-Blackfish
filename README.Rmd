---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# fuzzylink

<!-- badges: start -->
<!-- badges: end -->

The goal of the `fuzzylink` package is to allow users to merge datasets with fuzzy matches on identifying variables. Suppose, for example, you have the following two datasets: 

```{r, echo = FALSE}
library(tidyverse)
dfA <- tribble(~name, ~age,
               'Timothy B. Ryan', 28,
               'James J. Pointer', 40,
               'Jennifer C. Reilly', 32)

dfB <- tribble(~name, ~hobby,
               'Tim Ryan', 'Woodworking',
               'Jimmy Pointer', 'Guitar',
               'Jessica Renny', 'Camping')

```

```{r}
dfA
dfB
```

We would like a procedure that correctly identifies that the first two rows of `dfA` and `dfB` are likely to be matches, but not the third row. The `fuzzylink()` function can do so.

```{r, eval = FALSE}
df <- fuzzylink(dfA, dfB, by = 'name')
df
```

The procedure works by using *pretrained text embeddings* from OpenAI's GPT-3 to construct a measure of similarity for each pair of names. These similarity measures are then used as predictors in a statistical model to estimate the probability that two name pairs represent the same entity. In the guide below, I will walk step-by-step through what's going on under the hood when we call the `fuzzylink()` function.

## Installation

You can install the development version of `fuzzylink` from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("joeornstein/fuzzylink")
```

You will also need an account with OpenAI. You can sign up [here](https://beta.openai.com/signup), after which you'll need generate an API key [here](https://platform.openai.com/account/api-keys). I recommend adding this API key as a variable in your operating system environment called `OPENAI_API_KEY`; that way you won't risk leaking it by hard-coding it into your R scripts. The `fuzzylink` package will automatically look for your API key under that variable name, and will prompt you to enter the API key manually if it can't find one there. If you're unfamiliar with setting Environment Variables in your operating system, [here](https://dev.to/biplov/handling-passwords-and-secret-keys-using-environment-variables-2ei0) are some helpful instructions. Note that you may need to restart your computer after completing this step.

## Example

Let's look at the example from the introduction, and walk through the steps that `fuzzylink()` takes to join the two dataframes.

### Step 1: Embedding

First, the function encodes each unique string in `dfA` and `dfB` as a 1,536-dimensional vector called an *embedding*. You can learn more about embeddings [here](https://platform.openai.com/docs/guides/embeddings/embedding-models), but the basic idea is to represent text using a vector of real-valued numbers, such that vectors that are close to one another in space have similar meaning.

```{r}
library(fuzzylink)

strings_A <- unique(dfA$name)
strings_B <- unique(dfB$name)
embeddings <- get_embeddings(unique(c(strings_A, strings_B)))

dim(embeddings)
rownames(embeddings)
```

### Step 2: Similarity Scores

```{r}
sim <- get_similarity_matrix(embeddings, strings_A, strings_B)
sim
```

### Step 3: Create a Training Set

```{r}
train <- get_training_set(sim)
train
```

### Step 4: Fit Model

```{r}
model <- glm(as.numeric(match == 'Yes') ~ sim, 
             data = train,
             family = 'binomial')
```

### Step 5: Create Matched Dataset

```{r}
df <- sim |> 
  reshape2::melt() |> 
  set_names(c('A', 'B', 'sim'))

df$match_probability <- predict(model, df, type = 'response')

head(df)

matches <- df |> 
  filter(match_probability > 0.2) |> 
  right_join(dfA, by = c('A' = 'name')) |> 
  left_join(dfB, by = c('B' = 'name')) |> 
  # join with match labels for those pairs in the training set
  left_join(train)
```

### Step 6: Validate Uncertain Matches

For every match within a range of match probabilities (by default 0.2 to 0.9), use an LLM prompt to validate whether the name pair is a match or not, just like we did with the training data.

```{r}
matches_to_validate <- matches |> 
  filter(match_probability > 0.2, 
         match_probability < 0.9,
         is.na(match))

matches_to_validate$match <- check_match(matches_to_validate$A,
                                         matches_to_validate$B)
# append new labeled pairs to the train set
train <- train |> 
  bind_rows(matches_to_validate |> 
              select(A,B,sim,match))

# refine the model
model <- glm(as.numeric(match == 'Yes') ~ sim,
             data = train,
             family = 'binomial')

df$match_probability <- predict(model, df, type = 'response')

matches <- df |> 
  filter(match_probability > 0.2) |> 
  right_join(dfA, by = c('A' = 'name')) |> 
  left_join(dfB, by = c('B' = 'name')) |> 
  # join with match labels for those pairs in the training set
  left_join(train)

matches
```
